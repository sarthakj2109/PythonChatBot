{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sarth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sarth\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 documents\n",
      "84 classes ['1-2 kg', '1024', '10th Gen i3', '10th Gen i5', '10th Gen i7', '128', '128+1024', '13.3 inches', '14 inches', '15.6 inches', '16GB RAM', '17.3 inches', '2048', '24GB RAM', '256', '256+1024', '256+2048', '2GB GPU', '32GB RAM', '3GB GPU', '4GB GPU', '4GB RAM', '512', '512+1024', '512+2048', '6GB GPU', '6th Gen i7', '7th Gen i3', '7th Gen i5', '7th Gen i7', '8GB GPU', '8GB RAM', '8th Gen i3', '8th Gen i5', '8th Gen i7', '8th Gen i9', '9th Gen i5', '9th Gen i7', '9th Gen i9', '>2 kg', 'AMD', 'ASUS', 'Acer', 'Apple', 'Business', 'Convertible', 'Dedicated', 'Dell', 'FAQ1', 'FAQ2', 'FAQ3', 'FAQ4', 'FAQ5', 'FAQ7', 'FAQ8', 'Gaming', 'HDD', 'HDD+SSD', 'HP', 'Integrated', 'Intel', 'Lenovo', 'Less than 1 kg', 'MSI', 'Notebook', 'Razer', 'Ryzen 3', 'Ryzen 5', 'Ryzen 7', 'SSD', 'Ultrabook', 'contact_us', 'download_cerificate', 'goodbye', 'greeting', 'language', 'options', 'predict_laptop_price', 'reschedule', 'search_centre', 'slot_booking', 'stats', 'thanks', 'verify_certificate']\n",
      "277 unique lemmatized words [\"'\", \"''\", \"'no\", \"'s\", '+', '+1024', '+2048', ',', '.', '1', '1-2', '1024', '10th', '128', '128+1024', '13.3', '14', '14.0', '15.6', '16', '17.3', '19', '1kg', '2', '2048', '24', '256', '256+1024', '256+2048', '3', '32', '4', '5', '512', '512+1024', '512+2048', '6', '6th', '7', '7th', '8', '8th', '9th', '<', 'a', 'aadhaar', 'acer', 'adhaar', 'administered', 'am', 'amd', 'an', 'and', 'any', 'anyone', 'anything', 'apple', 'appointment', 'are', 'asus', 'at', 'availability', 'available', 'awesome', 'be', 'being', 'book', 'booked', 'booking', 'both', 'business', 'buy', 'by', 'bye', 'ca', 'can', 'card', 'centre', 'cerificate', 'certificate', 'change', 'charge', 'chatting', 'cheated', 'check', 'click', 'combination', 'compulsory', 'confirmation', 'contact', 'convertible', 'cost', 'costly', 'could', 'covid', 'cowin', 'date', 'day', 'dell', 'detail', 'disk', 'district', 'do', 'document', 'download', 'drive', 'each', 'english', 'external', 'fake', 'family', 'fee', 'feel', 'for', 'free', 'gaming', 'gb', 'gen', 'get', 'good', 'goodbye', 'google', 'gpu', 'graphic', 'hard', 'have', 'hdd', 'hdd+ssd', 'heavier', 'hello', 'help', 'helpful', 'helping', 'helpline', 'hey', 'hi', 'hindi', 'hola', 'how', 'hp', 'i', 'i3', 'i5', 'i7', 'i9', 'in', 'inch', 'information', 'integrated', 'intel', 'internal', 'is', 'issue', 'it', 'kg', 'kilo', 'know', 'language', 'laptop', 'later', 'le', 'lenovo', 'location', 'looking', 'macbook', 'manadatory', 'manage', 'mandatory', 'many', 'map', 'me', 'member', 'messgae', 'minimum', 'missed', 'mobile', 'msi', 'my', \"n't\", 'near', 'need', 'next', 'nice', 'no', 'not', 'notebook', 'number', 'of', 'offered', 'ok', 'on', 'one', 'online', 'page', 'paid', 'payment', 'people', 'period', 'phone', 'pincode', 'please', 'portal', 'predict', 'prediction', 'preferance', 'price', 'procedure', 'provide', 'ram', 'razer', 'read', 'real', 'rebook', 'receive', 'register', 'registered', 'registration', 'require', 'required', 'reschedule', 'rescheduling', 'ryzen', 'search', 'see', 'shot', 'show', 'slot', 'solid', 'specific', 'ssd', 'state', 'statewise', 'statistic', 'stats', 'step', 'storage', 'stuck', 'support', 'taken', 'tb', 'than', 'thank', 'thanks', 'that', 'the', 'theprice', 'there', 'think', 'this', 'through', 'till', 'time', 'to', 'type', 'ultrabook', 'understand', 'using', 'vaccinated', 'vaccination', 'vaccine', 'valid', 'verification', 'verify', 'view', 'want', 'website', 'weight', 'what', 'when', 'where', 'whether', 'will', 'wish', 'with', 'without', 'you', 'your']\n",
      "Training data created\n",
      "Epoch 1/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 20s - loss: 4.4295 - accuracy: 0.0000e+00\n",
      "49/49 [==============================] - 0s 854us/step - loss: 4.4233 - accuracy: 0.0016\n",
      "Epoch 2/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 4.4422 - accuracy: 0.0000e+00\n",
      "49/49 [==============================] - 0s 1ms/step - loss: 4.3959 - accuracy: 0.0214\n",
      "Epoch 3/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 4.2056 - accuracy: 0.0000e+00\n",
      "41/49 [========================>.....] - ETA: 0s - loss: 4.2888 - accuracy: 0.0388    \n",
      "49/49 [==============================] - 0s 1ms/step - loss: 4.2904 - accuracy: 0.0381\n",
      "Epoch 4/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 4.3265 - accuracy: 0.0000e+00\n",
      "49/49 [==============================] - 0s 1000us/step - loss: 4.2725 - accuracy: 0.0594\n",
      "Epoch 5/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 4.5230 - accuracy: 0.0000e+00\n",
      "49/49 [==============================] - 0s 729us/step - loss: 4.2194 - accuracy: 0.0974\n",
      "Epoch 6/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 3.5906 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 4.0479 - accuracy: 0.1305\n",
      "Epoch 7/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 3.5929 - accuracy: 0.0000e+00\n",
      "49/49 [==============================] - 0s 750us/step - loss: 4.0684 - accuracy: 0.0644\n",
      "Epoch 8/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 4.2226 - accuracy: 0.0000e+00\n",
      "49/49 [==============================] - 0s 729us/step - loss: 3.9347 - accuracy: 0.0929\n",
      "Epoch 9/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 3.6690 - accuracy: 0.0000e+00\n",
      "49/49 [==============================] - 0s 771us/step - loss: 3.6994 - accuracy: 0.1131\n",
      "Epoch 10/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 3.0670 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 813us/step - loss: 3.6382 - accuracy: 0.1948\n",
      "Epoch 11/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 2.9812 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 896us/step - loss: 3.4529 - accuracy: 0.1995\n",
      "Epoch 12/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 3.7671 - accuracy: 0.0000e+00\n",
      "49/49 [==============================] - 0s 771us/step - loss: 3.3984 - accuracy: 0.2065\n",
      "Epoch 13/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 3.3254 - accuracy: 0.2000\n",
      "49/49 [==============================] - 0s 792us/step - loss: 3.1967 - accuracy: 0.2285\n",
      "Epoch 14/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 2.4165 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 688us/step - loss: 2.9356 - accuracy: 0.2912\n",
      "Epoch 15/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 2.8064 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 2.9586 - accuracy: 0.2548\n",
      "Epoch 16/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 3.5090 - accuracy: 0.2000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 2.8015 - accuracy: 0.3081\n",
      "Epoch 17/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 2.1382 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 2.5879 - accuracy: 0.3652\n",
      "Epoch 18/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 3.4834 - accuracy: 0.0000e+00\n",
      "49/49 [==============================] - 0s 646us/step - loss: 2.5596 - accuracy: 0.3412\n",
      "Epoch 19/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 3.1866 - accuracy: 0.2000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 2.4455 - accuracy: 0.3866\n",
      "Epoch 20/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 2.3734 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 2.2684 - accuracy: 0.4288\n",
      "Epoch 21/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.1400 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 2.1294 - accuracy: 0.4865\n",
      "Epoch 22/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 2.4415 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 2.2035 - accuracy: 0.4230\n",
      "Epoch 23/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 2.1481 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 1.9835 - accuracy: 0.4947\n",
      "Epoch 24/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 2.1779 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 1.8527 - accuracy: 0.5056\n",
      "Epoch 25/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.7764 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 1.6768 - accuracy: 0.5423\n",
      "Epoch 26/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.8175 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 1.8361 - accuracy: 0.4831\n",
      "Epoch 27/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 2.2137 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 1.8276 - accuracy: 0.5048\n",
      "Epoch 28/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.3189 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 1.6361 - accuracy: 0.5379\n",
      "Epoch 29/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.1824 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 1.4647 - accuracy: 0.6314\n",
      "Epoch 30/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.7462 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 1.2908 - accuracy: 0.6781\n",
      "Epoch 31/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.1823 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 630us/step - loss: 1.4360 - accuracy: 0.5720\n",
      "Epoch 32/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.8848 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 667us/step - loss: 1.3314 - accuracy: 0.6148\n",
      "Epoch 33/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 2.0783 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 1.3628 - accuracy: 0.6073\n",
      "Epoch 34/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.3462 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 1.3206 - accuracy: 0.6557\n",
      "Epoch 35/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.8652 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 1.4024 - accuracy: 0.6003\n",
      "Epoch 36/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.9721 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 1.2179 - accuracy: 0.6743\n",
      "Epoch 37/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.1045 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 1.2389 - accuracy: 0.6511\n",
      "Epoch 38/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.9068 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 1.0091 - accuracy: 0.7387\n",
      "Epoch 39/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.5102 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 667us/step - loss: 1.0338 - accuracy: 0.6958\n",
      "Epoch 40/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.3365 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 667us/step - loss: 1.0700 - accuracy: 0.7034\n",
      "Epoch 41/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5715 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 667us/step - loss: 1.0062 - accuracy: 0.6630\n",
      "Epoch 42/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.1674 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.8683 - accuracy: 0.7581\n",
      "Epoch 43/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.5486 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 1.1329 - accuracy: 0.6689\n",
      "Epoch 44/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.0063 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 1.0892 - accuracy: 0.6484\n",
      "Epoch 45/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5450 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 1.0208 - accuracy: 0.7154\n",
      "Epoch 46/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.8075 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 1.0121 - accuracy: 0.7522\n",
      "Epoch 47/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 2.2740 - accuracy: 0.2000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 1.0284 - accuracy: 0.6618\n",
      "Epoch 48/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.6204 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.7691 - accuracy: 0.7871\n",
      "Epoch 49/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.2775 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 713us/step - loss: 0.7948 - accuracy: 0.7679\n",
      "Epoch 50/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.6831 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.6892 - accuracy: 0.8193\n",
      "Epoch 51/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.7292 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 0.9022 - accuracy: 0.7258\n",
      "Epoch 52/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.0792 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.8107 - accuracy: 0.7592\n",
      "Epoch 53/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3240 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 0.7002 - accuracy: 0.8208\n",
      "Epoch 54/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.6085 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 0.8258 - accuracy: 0.7541\n",
      "Epoch 55/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.1794 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 0.8121 - accuracy: 0.7160\n",
      "Epoch 56/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.7037 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 0.8767 - accuracy: 0.7291\n",
      "Epoch 57/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1681 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.7146 - accuracy: 0.7959\n",
      "Epoch 58/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.2042 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.8735 - accuracy: 0.7370\n",
      "Epoch 59/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.8926 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.7055 - accuracy: 0.8178\n",
      "Epoch 60/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2529 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.6293 - accuracy: 0.7979\n",
      "Epoch 61/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.9781 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.7591 - accuracy: 0.7699\n",
      "Epoch 62/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.6178 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.6865 - accuracy: 0.7948\n",
      "Epoch 63/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0499 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.4759 - accuracy: 0.8534\n",
      "Epoch 64/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3319 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.6757 - accuracy: 0.7994\n",
      "Epoch 65/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1213 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 671us/step - loss: 0.6892 - accuracy: 0.8138\n",
      "Epoch 66/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.1425 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.6263 - accuracy: 0.7730\n",
      "Epoch 67/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.6711 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.7716 - accuracy: 0.7876\n",
      "Epoch 68/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2344 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.5502 - accuracy: 0.8090\n",
      "Epoch 69/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.7820 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.7196 - accuracy: 0.7980\n",
      "Epoch 70/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.4868 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.7641 - accuracy: 0.7778\n",
      "Epoch 71/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.4277 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.5847 - accuracy: 0.8120\n",
      "Epoch 72/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.4545 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.6557 - accuracy: 0.8143\n",
      "Epoch 73/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.4731 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.7068 - accuracy: 0.7979\n",
      "Epoch 74/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3994 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.5191 - accuracy: 0.8434\n",
      "Epoch 75/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.7473 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 771us/step - loss: 0.6630 - accuracy: 0.7828\n",
      "Epoch 76/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.7569 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.6769 - accuracy: 0.7839\n",
      "Epoch 77/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.4624 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.6229 - accuracy: 0.8182\n",
      "Epoch 78/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3446 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 734us/step - loss: 0.6742 - accuracy: 0.8032\n",
      "Epoch 79/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3404 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.5456 - accuracy: 0.8164\n",
      "Epoch 80/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2692 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.5872 - accuracy: 0.8100\n",
      "Epoch 81/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.0071 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 688us/step - loss: 0.7097 - accuracy: 0.7758\n",
      "Epoch 82/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.7353 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.6699 - accuracy: 0.8161\n",
      "Epoch 83/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.1946 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 687us/step - loss: 0.6869 - accuracy: 0.8044\n",
      "Epoch 84/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.4486 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.7077 - accuracy: 0.7765\n",
      "Epoch 85/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0199 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.5171 - accuracy: 0.8383\n",
      "Epoch 86/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.1788 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 667us/step - loss: 0.6046 - accuracy: 0.7932\n",
      "Epoch 87/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.6212 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.3556 - accuracy: 0.8963\n",
      "Epoch 88/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.7063 - accuracy: 0.4000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.6623 - accuracy: 0.7895\n",
      "Epoch 89/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.7701 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.6097 - accuracy: 0.8122\n",
      "Epoch 90/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2052 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 708us/step - loss: 0.4380 - accuracy: 0.8856\n",
      "Epoch 91/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.1373 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.4632 - accuracy: 0.8537\n",
      "Epoch 92/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1088 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 687us/step - loss: 0.6471 - accuracy: 0.7948\n",
      "Epoch 93/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.6618 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 708us/step - loss: 0.5772 - accuracy: 0.8115\n",
      "Epoch 94/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0544 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 688us/step - loss: 0.5629 - accuracy: 0.8139\n",
      "Epoch 95/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3932 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.4616 - accuracy: 0.8523\n",
      "Epoch 96/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0940 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.4950 - accuracy: 0.8669\n",
      "Epoch 97/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5008 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 708us/step - loss: 0.3962 - accuracy: 0.8959\n",
      "Epoch 98/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1428 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.4728 - accuracy: 0.8386\n",
      "Epoch 99/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0962 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.6141 - accuracy: 0.8240\n",
      "Epoch 100/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2200 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 708us/step - loss: 0.5114 - accuracy: 0.8495\n",
      "Epoch 101/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2645 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 688us/step - loss: 0.4729 - accuracy: 0.8487\n",
      "Epoch 102/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.6720 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 687us/step - loss: 0.5899 - accuracy: 0.8391\n",
      "Epoch 103/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3090 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 688us/step - loss: 0.5505 - accuracy: 0.7956\n",
      "Epoch 104/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.3147 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 708us/step - loss: 0.5964 - accuracy: 0.8447\n",
      "Epoch 105/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5198 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.6456 - accuracy: 0.8277\n",
      "Epoch 106/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1112 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 708us/step - loss: 0.4906 - accuracy: 0.8448\n",
      "Epoch 107/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 708us/step - loss: 0.5023 - accuracy: 0.8431\n",
      "Epoch 108/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.9824 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.5626 - accuracy: 0.8171\n",
      "Epoch 109/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3951 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.4616 - accuracy: 0.8581\n",
      "Epoch 110/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5716 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.4023 - accuracy: 0.8646\n",
      "Epoch 111/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.9130 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 0.5771 - accuracy: 0.8376\n",
      "Epoch 112/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5919 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.5285 - accuracy: 0.8362\n",
      "Epoch 113/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5399 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.5857 - accuracy: 0.8216\n",
      "Epoch 114/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0411 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.4519 - accuracy: 0.8632\n",
      "Epoch 115/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1053 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.4183 - accuracy: 0.8831\n",
      "Epoch 116/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1131 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.4787 - accuracy: 0.8622\n",
      "Epoch 117/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3291 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 0.4513 - accuracy: 0.8541\n",
      "Epoch 118/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3112 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.4059 - accuracy: 0.8564\n",
      "Epoch 119/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0950 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.5151 - accuracy: 0.8462\n",
      "Epoch 120/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3237 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.4077 - accuracy: 0.8639\n",
      "Epoch 121/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.9930 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 0.6001 - accuracy: 0.8339\n",
      "Epoch 122/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.0260 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.4685 - accuracy: 0.8360\n",
      "Epoch 123/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1174 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.5296 - accuracy: 0.8415\n",
      "Epoch 124/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2989 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.4976 - accuracy: 0.8148\n",
      "Epoch 125/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1801 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 630us/step - loss: 0.5100 - accuracy: 0.8280\n",
      "Epoch 126/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1907 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 708us/step - loss: 0.4795 - accuracy: 0.8629\n",
      "Epoch 127/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.8139 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.7009 - accuracy: 0.8111\n",
      "Epoch 128/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2032 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.4925 - accuracy: 0.8531\n",
      "Epoch 129/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2857 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 583us/step - loss: 0.4118 - accuracy: 0.8307\n",
      "Epoch 130/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.4303 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.4548 - accuracy: 0.8479\n",
      "Epoch 131/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.4706 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.5674 - accuracy: 0.7936\n",
      "Epoch 132/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3804 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 0.5069 - accuracy: 0.8247\n",
      "Epoch 133/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.4447 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.4241 - accuracy: 0.8660\n",
      "Epoch 134/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1196 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 604us/step - loss: 0.4478 - accuracy: 0.8289\n",
      "Epoch 135/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5414 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 0.4751 - accuracy: 0.8422\n",
      "Epoch 136/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0492 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 771us/step - loss: 0.6008 - accuracy: 0.8118\n",
      "Epoch 137/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.6796 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.3697 - accuracy: 0.8603\n",
      "Epoch 138/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0963 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.4372 - accuracy: 0.8630\n",
      "Epoch 139/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.6712 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.5622 - accuracy: 0.8445\n",
      "Epoch 140/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0405 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 792us/step - loss: 0.4474 - accuracy: 0.8848\n",
      "Epoch 141/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2025 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.4679 - accuracy: 0.8711\n",
      "Epoch 142/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3055 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.5190 - accuracy: 0.8423\n",
      "Epoch 143/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3215 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 771us/step - loss: 0.6505 - accuracy: 0.7973\n",
      "Epoch 144/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.4827 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.3967 - accuracy: 0.8778\n",
      "Epoch 145/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3265 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 771us/step - loss: 0.4247 - accuracy: 0.8299\n",
      "Epoch 146/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0657 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.4194 - accuracy: 0.8599\n",
      "Epoch 147/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.8762 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.5865 - accuracy: 0.8094\n",
      "Epoch 148/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2657 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.4155 - accuracy: 0.8736\n",
      "Epoch 149/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0738 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 813us/step - loss: 0.3303 - accuracy: 0.9079\n",
      "Epoch 150/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1163 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 771us/step - loss: 0.3519 - accuracy: 0.8767\n",
      "Epoch 151/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0044 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.3508 - accuracy: 0.8617\n",
      "Epoch 152/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1488 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.3789 - accuracy: 0.8733\n",
      "Epoch 153/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.3400 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 792us/step - loss: 0.7583 - accuracy: 0.7794\n",
      "Epoch 154/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2145 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 791us/step - loss: 0.3577 - accuracy: 0.8747\n",
      "Epoch 155/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0442 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 834us/step - loss: 0.4146 - accuracy: 0.8599\n",
      "Epoch 156/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0482 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 792us/step - loss: 0.3908 - accuracy: 0.8680\n",
      "Epoch 157/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0135 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.4327 - accuracy: 0.8750\n",
      "Epoch 158/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.4510 - accuracy: 0.8540\n",
      "Epoch 159/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 771us/step - loss: 0.5721 - accuracy: 0.8236\n",
      "Epoch 160/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0966 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.5246 - accuracy: 0.8228\n",
      "Epoch 161/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.8323 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.4005 - accuracy: 0.8618\n",
      "Epoch 162/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.0919 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.5684 - accuracy: 0.8020\n",
      "Epoch 163/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.6917 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.4012 - accuracy: 0.8659\n",
      "Epoch 164/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0181 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.5317 - accuracy: 0.7826\n",
      "Epoch 165/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2700 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 771us/step - loss: 0.3298 - accuracy: 0.8739\n",
      "Epoch 166/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1959 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 750us/step - loss: 0.3731 - accuracy: 0.8621\n",
      "Epoch 167/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0261 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.3637 - accuracy: 0.8699\n",
      "Epoch 168/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.4291 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.6216 - accuracy: 0.8088\n",
      "Epoch 169/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0105 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 708us/step - loss: 0.4433 - accuracy: 0.8844\n",
      "Epoch 170/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0902 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.3950 - accuracy: 0.8659\n",
      "Epoch 171/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2652 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.4372 - accuracy: 0.8744\n",
      "Epoch 172/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.4802 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.4586 - accuracy: 0.8416\n",
      "Epoch 173/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2939 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.3176 - accuracy: 0.8625\n",
      "Epoch 174/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.6133 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.6029 - accuracy: 0.8213\n",
      "Epoch 175/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5610 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 667us/step - loss: 0.4907 - accuracy: 0.8265\n",
      "Epoch 176/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0998 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.5324 - accuracy: 0.8514\n",
      "Epoch 177/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5320 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 667us/step - loss: 0.3377 - accuracy: 0.8823\n",
      "Epoch 178/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.4214 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 667us/step - loss: 0.4826 - accuracy: 0.8475\n",
      "Epoch 179/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.8700 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.6625 - accuracy: 0.8484\n",
      "Epoch 180/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 1.2560 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 812us/step - loss: 0.5351 - accuracy: 0.8243\n",
      "Epoch 181/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0225 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 896us/step - loss: 0.4589 - accuracy: 0.8800\n",
      "Epoch 182/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5049 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 979us/step - loss: 0.3774 - accuracy: 0.8816\n",
      "Epoch 183/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0949 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 958us/step - loss: 0.4172 - accuracy: 0.8438\n",
      "Epoch 184/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1363 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.4105 - accuracy: 0.8559\n",
      "Epoch 185/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5224 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 875us/step - loss: 0.4750 - accuracy: 0.8548\n",
      "Epoch 186/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2526 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 854us/step - loss: 0.4632 - accuracy: 0.8497\n",
      "Epoch 187/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.5588 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 833us/step - loss: 0.2700 - accuracy: 0.9046\n",
      "Epoch 188/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0702 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 917us/step - loss: 0.6005 - accuracy: 0.8346\n",
      "Epoch 189/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2802 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 792us/step - loss: 0.4192 - accuracy: 0.8493\n",
      "Epoch 190/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.7138 - accuracy: 0.6000\n",
      "49/49 [==============================] - 0s 771us/step - loss: 0.4459 - accuracy: 0.8213\n",
      "Epoch 191/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3577 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 729us/step - loss: 0.3975 - accuracy: 0.8512\n",
      "Epoch 192/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1950 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 688us/step - loss: 0.2581 - accuracy: 0.8825\n",
      "Epoch 193/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1510 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.3681 - accuracy: 0.8734\n",
      "Epoch 194/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.3251 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 688us/step - loss: 0.4188 - accuracy: 0.8317\n",
      "Epoch 195/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.4756 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.4190 - accuracy: 0.8577\n",
      "Epoch 196/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.2951 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.5713 - accuracy: 0.8061\n",
      "Epoch 197/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1330 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.5291 - accuracy: 0.8697\n",
      "Epoch 198/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.1185 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 667us/step - loss: 0.4834 - accuracy: 0.8320\n",
      "Epoch 199/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.0180 - accuracy: 1.0000\n",
      "49/49 [==============================] - 0s 646us/step - loss: 0.3877 - accuracy: 0.8661\n",
      "Epoch 200/200\n",
      "\n",
      " 1/49 [..............................] - ETA: 0s - loss: 0.6356 - accuracy: 0.8000\n",
      "49/49 [==============================] - 0s 625us/step - loss: 0.3595 - accuracy: 0.8530\n",
      "model created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 21:21:55.031467: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-11-07 21:21:55.031496: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-11-07 21:21:58.695228: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-07 21:21:58.696963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\n",
      "2021-11-07 21:21:59.705395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1\n",
      "coreClock: 1.442GHz coreCount: 6 deviceMemorySize: 3.00GiB deviceMemoryBandwidth: 78.32GiB/s\n",
      "2021-11-07 21:21:59.706537: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-11-07 21:21:59.707347: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n",
      "2021-11-07 21:21:59.708130: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n",
      "2021-11-07 21:21:59.744850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
      "2021-11-07 21:21:59.755807: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
      "2021-11-07 21:21:59.797335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
      "2021-11-07 21:21:59.798599: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n",
      "2021-11-07 21:21:59.799354: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2021-11-07 21:21:59.799368: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-11-07 21:21:59.803514: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 21:21:59.805384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-07 21:21:59.805399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "2021-11-07 21:21:59.805914: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-07 21:21:59.944860: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "!python train_chatbot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293 documents\n",
      "85 classes ['1-2 kg', '1024', '10th Gen i3', '10th Gen i5', '10th Gen i7', '128', '128+1024', '13.3 inches', '14 inches', '15.6 inches', '16GB RAM', '17.3 inches', '2048', '24GB RAM', '256', '256+1024', '256+2048', '2GB GPU', '32GB RAM', '3GB GPU', '4GB GPU', '4GB RAM', '512', '512+1024', '512+2048', '6GB GPU', '6th Gen i7', '7th Gen i3', '7th Gen i5', '7th Gen i7', '8GB GPU', '8GB RAM', '8th Gen i3', '8th Gen i5', '8th Gen i7', '8th Gen i9', '9th Gen i5', '9th Gen i7', '9th Gen i9', '>2 kg', 'AMD', 'ASUS', 'Acer', 'Apple', 'Business', 'Convertible', 'Dedicated', 'Dell', 'Gaming', 'HDD', 'HDD+SSD', 'HP', 'Integrated', 'Intel', 'Lenovo', 'Less than 1 kg', 'MSI', 'Notebook', 'Razer', 'Ryzen 3', 'Ryzen 5', 'Ryzen 7', 'SSD', 'Ultrabook', 'goodbye', 'greeting', 'info_Display', 'info_OS', 'info_Processor', 'info_Scr', 'info_features', 'info_gpu', 'info_hdd', 'info_processor', 'info_ram', 'info_ss', 'info_ssd', 'info_ssd+hdd', 'info_storage', 'info_type', 'options', 'performance', 'predict_laptop_price', 'thanks', 'things_to_consider']\n",
      "213 unique lemmatized words [\"''\", \"'s\", '+', '+1024', '+2048', '+hdd', '+ssd', ',', '.', '0.75kg', '1', '1-2', '1000', '1024', '1024gb', '10th', '128', '128+1024', '128gb', '13.3', '14', '14.0', '15.6', '16', '16gb', '17.3', '1kg', '2', '2048', '2048gb', '24', '24gb', '250', '256', '256+1024', '256+2048', '256gb', '2kg', '3', '32', '32gb', '4', '4gb', '5', '500', '512', '512+1024', '512+2048', '512gb', '6', '6th', '7', '7th', '8', '8gb', '8th', '9th', '<', '>', 'a', 'about', 'acer', 'again', 'am', 'amd', 'an', 'and', 'anyone', 'anything', 'apple', 'are', 'asus', 'awesome', 'both', 'business', 'buy', 'buying', 'by', 'bye', 'can', 'card', 'chatting', 'choose', 'combination', 'consider', 'convertible', 'correct', 'costly', 'day', 'dell', 'depends', 'disk', 'display', 'do', 'drive', 'external', 'feature', 'for', 'gaming', 'gb', 'gen', 'give', 'good', 'goodbye', 'gpu', 'graphic', 'guide', 'hard', 'have', 'hdd', 'hdd+', 'hdd+ssd', 'heavier', 'heavy', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'hola', 'how', 'hp', 'i', 'i3', 'i5', 'i7', 'i9', 'inch', 'info', 'integrated', 'intel', 'internal', 'is', 'issue', 'kg', 'kilo', 'know', 'laptop', 'later', 'le', 'lenovo', 'light', 'looking', 'macbook', 'me', 'mean', 'measure', 'minimum', 'more', 'msi', 'my', \"n't\", 'need', 'next', 'nice', 'no', 'normal', 'not', 'notebook', 'o', 'of', 'ok', 'on', 'operating', 'option', 'other', 'perfect', 'performance', 'predict', 'prediction', 'preferance', 'price', 'processor', 'ram', 'razer', 'require', 'required', 'right', 'ryzen', 'screen', 'see', 'shall', 'size', 'solid', 'ssd', 'ssd+', 'ssd+hdd', 'state', 'storage', 'system', 'tb', 'than', 'thank', 'thanks', 'that', 'the', 'there', 'thing', 'till', 'time', 'to', 'type', 'ultrabook', 'v', 'want', 'weight', 'what', 'when', 'will', 'wish', 'with', 'you']\n",
      "Training data created\n",
      "Epoch 1/200\n",
      "59/59 [==============================] - 1s 4ms/step - loss: 4.4585 - accuracy: 0.0103\n",
      "Epoch 2/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 4.4044 - accuracy: 0.0099\n",
      "Epoch 3/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 4.3218 - accuracy: 0.0241\n",
      "Epoch 4/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 4.2511 - accuracy: 0.0381\n",
      "Epoch 5/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 4.2034 - accuracy: 0.0221TA: 0s - loss: 4.1947 - accuracy: 0.\n",
      "Epoch 6/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 4.0355 - accuracy: 0.0513\n",
      "Epoch 7/200\n",
      "59/59 [==============================] - ETA: 0s - loss: 3.9489 - accuracy: 0.08 - 0s 4ms/step - loss: 3.9540 - accuracy: 0.0801\n",
      "Epoch 8/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 3.9071 - accuracy: 0.0675\n",
      "Epoch 9/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 3.8554 - accuracy: 0.0775\n",
      "Epoch 10/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 3.7693 - accuracy: 0.0781\n",
      "Epoch 11/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 3.4074 - accuracy: 0.1442\n",
      "Epoch 12/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 3.3932 - accuracy: 0.2033\n",
      "Epoch 13/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 3.2764 - accuracy: 0.1728\n",
      "Epoch 14/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 3.1117 - accuracy: 0.2620\n",
      "Epoch 15/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 3.0919 - accuracy: 0.2287\n",
      "Epoch 16/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 2.9861 - accuracy: 0.2209\n",
      "Epoch 17/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 2.8444 - accuracy: 0.2788\n",
      "Epoch 18/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 2.6548 - accuracy: 0.2854\n",
      "Epoch 19/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 2.5645 - accuracy: 0.2997\n",
      "Epoch 20/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 2.4267 - accuracy: 0.3866\n",
      "Epoch 21/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.4569 - accuracy: 0.3346\n",
      "Epoch 22/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 2.2939 - accuracy: 0.4025\n",
      "Epoch 23/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 2.3669 - accuracy: 0.3848\n",
      "Epoch 24/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 2.0471 - accuracy: 0.4283\n",
      "Epoch 25/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 2.1585 - accuracy: 0.3751\n",
      "Epoch 26/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 2.0279 - accuracy: 0.4577\n",
      "Epoch 27/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.8306 - accuracy: 0.4730\n",
      "Epoch 28/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.9116 - accuracy: 0.4620\n",
      "Epoch 29/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.7856 - accuracy: 0.5020\n",
      "Epoch 30/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.6942 - accuracy: 0.5066\n",
      "Epoch 31/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.6015 - accuracy: 0.5690\n",
      "Epoch 32/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5460 - accuracy: 0.5974\n",
      "Epoch 33/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.5470 - accuracy: 0.5292\n",
      "Epoch 34/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.6013 - accuracy: 0.5682\n",
      "Epoch 35/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.5178 - accuracy: 0.5836\n",
      "Epoch 36/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.1627 - accuracy: 0.7047\n",
      "Epoch 37/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.2360 - accuracy: 0.6142\n",
      "Epoch 38/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.2685 - accuracy: 0.6058\n",
      "Epoch 39/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.3479 - accuracy: 0.5909\n",
      "Epoch 40/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.2465 - accuracy: 0.6577\n",
      "Epoch 41/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.2945 - accuracy: 0.6023\n",
      "Epoch 42/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.1162 - accuracy: 0.6476\n",
      "Epoch 43/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2031 - accuracy: 0.6084\n",
      "Epoch 44/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.0787 - accuracy: 0.7032\n",
      "Epoch 45/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1194 - accuracy: 0.6509\n",
      "Epoch 46/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.2522 - accuracy: 0.6359\n",
      "Epoch 47/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 1.0442 - accuracy: 0.7048\n",
      "Epoch 48/200\n",
      "59/59 [==============================] - 0s 6ms/step - loss: 0.9859 - accuracy: 0.6992\n",
      "Epoch 49/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 1.1519 - accuracy: 0.6964\n",
      "Epoch 50/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.1339 - accuracy: 0.6379\n",
      "Epoch 51/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0797 - accuracy: 0.6966\n",
      "Epoch 52/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.7198\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0148 - accuracy: 0.7389\n",
      "Epoch 54/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.1012 - accuracy: 0.7035\n",
      "Epoch 55/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 1.3758 - accuracy: 0.5618\n",
      "Epoch 56/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.9541 - accuracy: 0.6888\n",
      "Epoch 57/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.9968 - accuracy: 0.6943: 0s - loss: 0.9960 - accuracy: 0.69\n",
      "Epoch 58/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 1.0755 - accuracy: 0.6807\n",
      "Epoch 59/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.9606 - accuracy: 0.7017\n",
      "Epoch 60/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8920 - accuracy: 0.7345\n",
      "Epoch 61/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7656 - accuracy: 0.7561: 0s - loss: 0.7357 - accuracy: 0.\n",
      "Epoch 62/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.9152 - accuracy: 0.6993: 0s - loss: 0.8449 - accuracy\n",
      "Epoch 63/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8347 - accuracy: 0.7160: 0s - loss: 0.8316 - accuracy: 0.71\n",
      "Epoch 64/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.7522 - accuracy: 0.7674\n",
      "Epoch 65/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.8695 - accuracy: 0.7462\n",
      "Epoch 66/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8580 - accuracy: 0.7248\n",
      "Epoch 67/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8578 - accuracy: 0.7240\n",
      "Epoch 68/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7264 - accuracy: 0.7330\n",
      "Epoch 69/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8579 - accuracy: 0.7299\n",
      "Epoch 70/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.9581 - accuracy: 0.6908\n",
      "Epoch 71/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7336 - accuracy: 0.7519\n",
      "Epoch 72/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6962 - accuracy: 0.7757\n",
      "Epoch 73/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8193 - accuracy: 0.7455\n",
      "Epoch 74/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6914 - accuracy: 0.7978\n",
      "Epoch 75/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7050 - accuracy: 0.7607\n",
      "Epoch 76/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.7533\n",
      "Epoch 77/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8978 - accuracy: 0.6877\n",
      "Epoch 78/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.8096\n",
      "Epoch 79/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7723 - accuracy: 0.7119\n",
      "Epoch 80/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6582 - accuracy: 0.7810\n",
      "Epoch 81/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6660 - accuracy: 0.7667\n",
      "Epoch 82/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6834 - accuracy: 0.7769\n",
      "Epoch 83/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6230 - accuracy: 0.7928\n",
      "Epoch 84/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.8600 - accuracy: 0.7194\n",
      "Epoch 85/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7650 - accuracy: 0.7576\n",
      "Epoch 86/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.7738\n",
      "Epoch 87/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.7968\n",
      "Epoch 88/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.7884\n",
      "Epoch 89/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.8213\n",
      "Epoch 90/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.7602 - accuracy: 0.7379\n",
      "Epoch 91/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.7473 - accuracy: 0.7507\n",
      "Epoch 92/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.8257\n",
      "Epoch 93/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.8102\n",
      "Epoch 94/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.8072\n",
      "Epoch 95/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.7772\n",
      "Epoch 96/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7341 - accuracy: 0.7502\n",
      "Epoch 97/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6983 - accuracy: 0.7803\n",
      "Epoch 98/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5597 - accuracy: 0.8141\n",
      "Epoch 99/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.7802\n",
      "Epoch 100/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.8097\n",
      "Epoch 101/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5960 - accuracy: 0.8401\n",
      "Epoch 102/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6610 - accuracy: 0.7807\n",
      "Epoch 103/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.6340 - accuracy: 0.7870\n",
      "Epoch 104/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.7088 - accuracy: 0.7693\n",
      "Epoch 105/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.7673\n",
      "Epoch 106/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7678 - accuracy: 0.7598\n",
      "Epoch 107/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.8098\n",
      "Epoch 108/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.6780 - accuracy: 0.7967\n",
      "Epoch 109/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.7897\n",
      "Epoch 110/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.8059\n",
      "Epoch 111/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5694 - accuracy: 0.8047\n",
      "Epoch 112/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.8258\n",
      "Epoch 113/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6681 - accuracy: 0.8093\n",
      "Epoch 114/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5847 - accuracy: 0.8184\n",
      "Epoch 115/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.6774 - accuracy: 0.7858\n",
      "Epoch 116/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.8162\n",
      "Epoch 117/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.8278\n",
      "Epoch 118/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.8400\n",
      "Epoch 119/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.7782\n",
      "Epoch 120/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.8186\n",
      "Epoch 121/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5153 - accuracy: 0.8060\n",
      "Epoch 122/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5281 - accuracy: 0.8119\n",
      "Epoch 123/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5374 - accuracy: 0.8204\n",
      "Epoch 124/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5840 - accuracy: 0.8140\n",
      "Epoch 125/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.7972\n",
      "Epoch 126/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6477 - accuracy: 0.7706\n",
      "Epoch 127/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.6275 - accuracy: 0.7977\n",
      "Epoch 128/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5245 - accuracy: 0.8205\n",
      "Epoch 129/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.7734\n",
      "Epoch 130/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.8143\n",
      "Epoch 131/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5820 - accuracy: 0.7963\n",
      "Epoch 132/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6952 - accuracy: 0.7657\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5485 - accuracy: 0.8374\n",
      "Epoch 134/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.6479 - accuracy: 0.8136\n",
      "Epoch 135/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7585 - accuracy: 0.7403\n",
      "Epoch 136/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.7959\n",
      "Epoch 137/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.7736\n",
      "Epoch 138/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.8192\n",
      "Epoch 139/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.8152\n",
      "Epoch 140/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5839 - accuracy: 0.7767\n",
      "Epoch 141/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5257 - accuracy: 0.7971\n",
      "Epoch 142/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5554 - accuracy: 0.8488\n",
      "Epoch 143/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5642 - accuracy: 0.8233\n",
      "Epoch 144/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7572 - accuracy: 0.7573\n",
      "Epoch 145/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.8198\n",
      "Epoch 146/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.8056\n",
      "Epoch 147/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5259 - accuracy: 0.8055\n",
      "Epoch 148/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6686 - accuracy: 0.7679\n",
      "Epoch 149/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6457 - accuracy: 0.7794\n",
      "Epoch 150/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.8059\n",
      "Epoch 151/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8672\n",
      "Epoch 152/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.8144\n",
      "Epoch 153/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.7009 - accuracy: 0.7685\n",
      "Epoch 154/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.4869 - accuracy: 0.8335\n",
      "Epoch 155/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6046 - accuracy: 0.8146\n",
      "Epoch 156/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5118 - accuracy: 0.8363\n",
      "Epoch 157/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8462\n",
      "Epoch 158/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.8582\n",
      "Epoch 159/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5361 - accuracy: 0.8300\n",
      "Epoch 160/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.8008\n",
      "Epoch 161/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.8690\n",
      "Epoch 162/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.8164\n",
      "Epoch 163/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.8025\n",
      "Epoch 164/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.8630\n",
      "Epoch 165/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5164 - accuracy: 0.8267\n",
      "Epoch 166/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.3956 - accuracy: 0.8606\n",
      "Epoch 167/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5726 - accuracy: 0.8131\n",
      "Epoch 168/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.8446\n",
      "Epoch 169/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5805 - accuracy: 0.8408\n",
      "Epoch 170/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.7014 - accuracy: 0.7781\n",
      "Epoch 171/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.8575\n",
      "Epoch 172/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5247 - accuracy: 0.8133\n",
      "Epoch 173/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5366 - accuracy: 0.8076\n",
      "Epoch 174/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5839 - accuracy: 0.8056\n",
      "Epoch 175/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.8533\n",
      "Epoch 176/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5538 - accuracy: 0.7721\n",
      "Epoch 177/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.4633 - accuracy: 0.8496\n",
      "Epoch 178/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.4910 - accuracy: 0.8437\n",
      "Epoch 179/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.8601\n",
      "Epoch 180/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5722 - accuracy: 0.8375\n",
      "Epoch 181/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5230 - accuracy: 0.8235\n",
      "Epoch 182/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8293\n",
      "Epoch 183/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.8191\n",
      "Epoch 184/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5649 - accuracy: 0.8058\n",
      "Epoch 185/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.6497 - accuracy: 0.7771\n",
      "Epoch 186/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.6881 - accuracy: 0.8013: 0s - loss: 0.6613 - accuracy\n",
      "Epoch 187/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5170 - accuracy: 0.8088\n",
      "Epoch 188/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.8268\n",
      "Epoch 189/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5410 - accuracy: 0.8518\n",
      "Epoch 190/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8298\n",
      "Epoch 191/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.8234\n",
      "Epoch 192/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5939 - accuracy: 0.7830\n",
      "Epoch 193/200\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.7120 - accuracy: 0.7652\n",
      "Epoch 194/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.8309\n",
      "Epoch 195/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.8208\n",
      "Epoch 196/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.8332\n",
      "Epoch 197/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5724 - accuracy: 0.8326\n",
      "Epoch 198/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.8083\n",
      "Epoch 199/200\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.7666\n",
      "Epoch 200/200\n",
      "59/59 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.8377\n",
      "model created\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from train_chatbot import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "acc = hist.history['accuracy']\n",
    "loss = hist.history['loss']\n",
    "epochs=200\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training Accuracy and Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'intent': 'predict_laptop_price', 'probability': '0.998606'}]\n",
      "[{'intent': 'Dell', 'probability': '0.99977463'}]\n",
      "found:  company\n",
      "set context to:  RAM\n",
      "[{'intent': '8GB RAM', 'probability': '0.6312273'}, {'intent': '8GB GPU', 'probability': '0.36689404'}]\n",
      "found:  RAM\n",
      "set context to:  Storage\n",
      "[{'intent': 'SSD', 'probability': '0.9997793'}]\n",
      "found:  Storage\n",
      "set context to:  SS\n",
      "[]\n",
      "[{'intent': '512', 'probability': '0.9994097'}]\n",
      "found:  SS\n",
      "set context to:  Processor\n",
      "[{'intent': 'Intel', 'probability': '0.9869919'}]\n",
      "found:  Processor\n",
      "set context to:  pdetails\n",
      "[{'intent': '9th Gen i5', 'probability': '0.9802793'}]\n",
      "found:  pdetails\n",
      "set context to:  GPU\n",
      "[{'intent': 'Dedicated', 'probability': '0.9998348'}]\n",
      "found:  GPU\n",
      "set context to:  Weight\n",
      "[{'intent': 'Less than 1 kg', 'probability': '0.9999305'}]\n",
      "found:  Weight\n",
      "set context to:  Screen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-07 22:10:43.890533: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-11-07 22:10:43.890562: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2021-11-07 22:10:47.499533: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-07 22:10:47.501115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\n",
      "2021-11-07 22:10:48.478364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1050 computeCapability: 6.1\n",
      "coreClock: 1.442GHz coreCount: 6 deviceMemorySize: 3.00GiB deviceMemoryBandwidth: 78.32GiB/s\n",
      "2021-11-07 22:10:48.479338: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2021-11-07 22:10:48.480128: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublas64_11.dll'; dlerror: cublas64_11.dll not found\n",
      "2021-11-07 22:10:48.480881: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cublasLt64_11.dll'; dlerror: cublasLt64_11.dll not found\n",
      "2021-11-07 22:10:48.486615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\n",
      "2021-11-07 22:10:48.488678: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\n",
      "2021-11-07 22:10:48.494289: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\n",
      "2021-11-07 22:10:48.495270: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusparse64_11.dll'; dlerror: cusparse64_11.dll not found\n",
      "2021-11-07 22:10:48.496069: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudnn64_8.dll'; dlerror: cudnn64_8.dll not found\n",
      "2021-11-07 22:10:48.496082: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-11-07 22:10:48.496341: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-07 22:10:48.496811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-07 22:10:48.496827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      \n",
      "2021-11-07 22:10:48.496855: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-07 22:10:57.149729: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "!python chatgui.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
